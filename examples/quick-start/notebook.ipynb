{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLRun Questioning Example\n",
    "\n",
    "This notebook demonstrates how to set up and use MLRun for questioning tasks.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup](#setup)\n",
    "2. [Deploy Controller](#deploy-controller)\n",
    "3. [Deploy Workflow](#deploy-workflow)\n",
    "4. [Ingest Data](#ingest-data)\n",
    "5. [Deploy UI](#deploy-ui)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before you begin, make sure you have completed the following steps:\n",
    "\n",
    "1. Install the required packages:\n",
    "   ```\n",
    "   !pip install -r requirements.txt\n",
    "   ```\n",
    "\n",
    "2. Install MLRun from the feature branch:\n",
    "   ```python\n",
    "   !pip install git+https://github.com/mlrun/genai-factory.git\n",
    "   ```\n",
    "\n",
    "3. Set up the necessary environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"\"  # Add your OpenAI base URL here\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"  # Add your OpenAI API key here\n",
    "os.environ[\"IS_LOCAL_CONFIG\"] = \"1\"\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "print(\"Environment variables set successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Controller\n",
    "\n",
    "This step will start the API controller server in a local Docker container and initialize the controller database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Workflow\n",
    "\n",
    "Now, we'll deploy the workflow using uvicorn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uvicorn pipeline:app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Data\n",
    "\n",
    "Here, we'll ingest the MLRun documentation data that we want to ask questions about later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m controller.src.main ingest -l web https://docs.mlrun.org/en/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy UI\n",
    "\n",
    "Finally, we'll deploy the user interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement UI deployment\n",
    "!npm run dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you have set up the MLRun questioning environment, you can start asking questions about the ingested MLRun documentation. Refer to the MLRun documentation for more information on how to use the questioning feature.\n",
    "\n",
    "If you encounter any issues or need further assistance, please consult the MLRun documentation or reach out to the MLRun community for support."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
